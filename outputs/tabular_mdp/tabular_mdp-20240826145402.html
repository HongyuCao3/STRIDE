<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<style>
.r1 {color: #800080; text-decoration-color: #800080}
.r2 {color: #ff00ff; text-decoration-color: #ff00ff}
.r3 {color: #800000; text-decoration-color: #800000}
.r4 {color: #800000; text-decoration-color: #800000; font-weight: bold}
.r5 {color: #008080; text-decoration-color: #008080; font-weight: bold}
.r6 {font-weight: bold}
.r7 {color: #808000; text-decoration-color: #808000}
body {
    color: #000000;
    background-color: #ffffff;
}
</style>
</head>
<body>
    <pre style="font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><code style="font-family:inherit">All outputs written to .<span class="r1">/outputs/tabular_mdp/</span><span class="r2">tabular_mdp-20240826145402.html</span>
<span class="r3">experiment </span><span class="r4">1</span><span class="r3">/</span><span class="r4">1</span><span class="r3"> ...</span>
<span class="r3">Start to play tabular_mdp</span>
<span class="r3">episode </span><span class="r4">1</span><span class="r3">/</span><span class="r4">1</span><span class="r3"> ...</span>
To agent:
Now you are going to play in a finite-horizon tabular Markov decision process, with length of horizon <span class="r5">5</span> <span class="r6">(</span>with time indices starting from <span class="r7">h</span>=<span class="r5">0</span> to <span class="r5">4</span><span class="r6">)</span>, number of states |S|=<span class="r5">3</span>, 
number of actions |A|=<span class="r5">3</span>. The transition matrix P is:
<span class="r6">[[[</span><span class="r5">1.00</span> <span class="r5">0.00</span> <span class="r5">0.00</span><span class="r6">]</span>
  <span class="r6">[</span><span class="r5">0.00</span> <span class="r5">0.00</span> <span class="r5">1.00</span><span class="r6">]</span>
  <span class="r6">[</span><span class="r5">1.00</span> <span class="r5">0.00</span> <span class="r5">0.00</span><span class="r6">]]</span>

 <span class="r6">[[</span><span class="r5">0.00</span> <span class="r5">1.00</span> <span class="r5">0.00</span><span class="r6">]</span>
  <span class="r6">[</span><span class="r5">0.00</span> <span class="r5">1.00</span> <span class="r5">0.00</span><span class="r6">]</span>
  <span class="r6">[</span><span class="r5">0.92</span> <span class="r5">0.08</span> <span class="r5">0.00</span><span class="r6">]]</span>

 <span class="r6">[[</span><span class="r5">0.90</span> <span class="r5">0.10</span> <span class="r5">0.00</span><span class="r6">]</span>
  <span class="r6">[</span><span class="r5">0.04</span> <span class="r5">0.48</span> <span class="r5">0.48</span><span class="r6">]</span>
  <span class="r6">[</span><span class="r5">1.00</span> <span class="r5">0.00</span> <span class="r5">0.00</span><span class="r6">]]]</span>
and reward matrix R is
<span class="r6">[[</span> <span class="r5">0.12</span>  <span class="r5">0.52</span>  <span class="r5">0.84</span><span class="r6">]</span>
 <span class="r6">[</span><span class="r5">-0.77</span> <span class="r5">-0.06</span>  <span class="r5">0.79</span><span class="r6">]</span>
 <span class="r6">[</span> <span class="r5">0.32</span> <span class="r5">-0.88</span> <span class="r5">-0.50</span><span class="r6">]]</span>

</code></pre>
</body>
</html>
